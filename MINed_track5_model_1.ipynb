{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#simple flow\n",
        "#->Environment setup by installed required libraries\n",
        "#->converting the whole pdf into images\n",
        "#->selecting only those images which are having table and cropping it\n",
        "#->now selected cropped images will be converted into csv files\n",
        "#->those csv files will be meaged into one txt\n",
        "#->it will be given to the input to langflow api for futher detection\n"
      ],
      "metadata": {
        "id": "mhEjVUbiUytV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#taken company->utiasset"
      ],
      "metadata": {
        "id": "YT2tYoFH3GTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Environment Setup***"
      ],
      "metadata": {
        "id": "rIWUwx-lzadT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "LoK74TVyzXsH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddlepaddle-gpu==2.5.2\n",
        "!pip install paddlepaddle-gpu==2.3.0.post110 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
        "!pip install pdf2image\n",
        "!apt-get update\n",
        "!apt-get install poppler-util\n",
        "!pip install pdf2image\n",
        "!apt-get update\n",
        "!apt-get install poppler-utils\n",
        "#!python3 -m pip install paddlepaddle-gpu\n",
        "!pip install \"paddleocr>=2.0.1\"\n",
        "!pip install protobuf==3.20.0\n",
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
        "!wget https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl\n",
        "!pip install -U layoutparser-0.0.0-py3-none-any.whl"
      ],
      "metadata": {
        "id": "JejuCeNXHckg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0be91615-da0f-4277-da47-e013ab025239",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: paddlepaddle-gpu==2.5.2 in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.2) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.2) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.2) (11.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.2) (4.4.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.2) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.2) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle-gpu==2.5.2) (4.25.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->paddlepaddle-gpu==2.5.2) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->paddlepaddle-gpu==2.5.2) (1.3.1)\n",
            "Looking in links: https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement paddlepaddle-gpu==2.3.0.post110 (from versions: 2.5.1, 2.5.1.post102, 2.5.1.post112, 2.5.1.post116, 2.5.1.post117, 2.5.1.post120, 2.5.2, 2.5.2.post102, 2.5.2.post112, 2.5.2.post116, 2.5.2.post117, 2.5.2.post120, 2.6.0, 2.6.0.post112, 2.6.0.post116, 2.6.0.post117, 2.6.0.post120, 2.6.1, 2.6.1.post112, 2.6.1.post116, 2.6.1.post117, 2.6.1.post120, 2.6.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for paddlepaddle-gpu==2.3.0.post110\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,306 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,640 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,229 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,904 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,604 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,521 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,647 kB]\n",
            "Fetched 21.2 MB in 5s (4,423 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package poppler-util\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 1s (140 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 124950 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting paddleocr>=2.0.1\n",
            "  Downloading paddleocr-2.9.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (2.0.6)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (0.25.1)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (0.4.0)\n",
            "Collecting pyclipper (from paddleocr>=2.0.1)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting lmdb (from paddleocr>=2.0.1)\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (4.67.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (1.26.4)\n",
            "Collecting rapidfuzz (from paddleocr>=2.0.1)\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (4.10.0.84)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (4.10.0.84)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (3.0.11)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (11.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (6.0.2)\n",
            "Collecting python-docx (from paddleocr>=2.0.1)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (4.12.3)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (4.55.7)\n",
            "Collecting fire>=0.3.0 (from paddleocr>=2.0.1)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from paddleocr>=2.0.1) (2.32.3)\n",
            "Collecting albumentations==1.4.10 (from paddleocr>=2.0.1)\n",
            "  Downloading albumentations-1.4.10-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting albucore==0.0.13 (from paddleocr>=2.0.1)\n",
            "  Downloading albucore-0.0.13-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting tomli>=2.0.1 (from albucore==0.0.13->paddleocr>=2.0.1)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.13->paddleocr>=2.0.1) (4.12.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.13->paddleocr>=2.0.1) (4.11.0.86)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr>=2.0.1) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr>=2.0.1) (1.6.1)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr>=2.0.1) (2.10.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.3.0->paddleocr>=2.0.1) (2.5.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr>=2.0.1) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr>=2.0.1) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr>=2.0.1) (2025.1.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr>=2.0.1) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr>=2.0.1) (0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->paddleocr>=2.0.1) (2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug->paddleocr>=2.0.1) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug->paddleocr>=2.0.1) (3.10.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx->paddleocr>=2.0.1) (5.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr>=2.0.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr>=2.0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr>=2.0.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr>=2.0.1) (2024.12.14)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr>=2.0.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr>=2.0.1) (2.27.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr>=2.0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr>=2.0.1) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr>=2.0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr>=2.0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr>=2.0.1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr>=2.0.1) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr>=2.0.1) (2.8.2)\n",
            "Downloading paddleocr-2.9.1-py3-none-any.whl (544 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.7/544.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.13-py3-none-any.whl (8.5 kB)\n",
            "Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=764b78e2e21c9fbeb9ab023b6961245c0d42fc5d6bb0a38f99fb47aa61d7e8f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: pyclipper, lmdb, tomli, rapidfuzz, python-docx, fire, albucore, albumentations, paddleocr\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.19\n",
            "    Uninstalling albucore-0.0.19:\n",
            "      Successfully uninstalled albucore-0.0.19\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "Successfully installed albucore-0.0.13 albumentations-1.4.10 fire-0.7.0 lmdb-1.6.2 paddleocr-2.9.1 pyclipper-1.3.0.post6 python-docx-1.1.2 rapidfuzz-3.12.1 tomli-2.2.1\n",
            "Collecting protobuf==3.20.0\n",
            "  Downloading protobuf-3.20.0-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.0-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "paddlepaddle-gpu 2.5.2 requires protobuf>=3.20.2; platform_system != \"Windows\", but you have protobuf 3.20.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigtable 2.28.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.19.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-spanner 3.51.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-pubsub 2.25.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ac261ada9ad846bdb70a893e1f249559"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PaddleOCR'...\n",
            "remote: Enumerating objects: 99136, done.\u001b[K\n",
            "remote: Counting objects: 100% (4127/4127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (515/515), done.\u001b[K\n",
            "remote: Total 99136 (delta 3845), reused 3773 (delta 3612), pack-reused 95009 (from 3)\u001b[K\n",
            "Receiving objects: 100% (99136/99136), 623.86 MiB | 17.27 MiB/s, done.\n",
            "Resolving deltas: 100% (75448/75448), done.\n",
            "Updating files: 100% (2024/2024), done.\n",
            "--2025-02-01 04:44:05--  https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl\n",
            "Resolving paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)... 103.235.47.176, 2409:8c04:1001:1203:0:ff:b0bb:4f27\n",
            "Connecting to paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)|103.235.47.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19145360 (18M) [application/octet-stream]\n",
            "Saving to: ‘layoutparser-0.0.0-py3-none-any.whl’\n",
            "\n",
            "layoutparser-0.0.0- 100%[===================>]  18.26M  15.7MB/s    in 1.2s    \n",
            "\n",
            "2025-02-01 04:44:08 (15.7 MB/s) - ‘layoutparser-0.0.0-py3-none-any.whl’ saved [19145360/19145360]\n",
            "\n",
            "Processing ./layoutparser-0.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from layoutparser==0.0.0) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from layoutparser==0.0.0) (4.10.0.84)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from layoutparser==0.0.0) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from layoutparser==0.0.0) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from layoutparser==0.0.0) (6.0.2)\n",
            "Collecting iopath (from layoutparser==0.0.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from layoutparser==0.0.0) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath->layoutparser==0.0.0) (4.12.2)\n",
            "Collecting portalocker (from iopath->layoutparser==0.0.0)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser==0.0.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->layoutparser==0.0.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->layoutparser==0.0.0) (1.17.0)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: iopath\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=07e7cdd99ad3f4475e8213f81f4b064b4cdaddda39efa85d55fc7cd468e96b60\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built iopath\n",
            "Installing collected packages: portalocker, iopath, layoutparser\n",
            "Successfully installed iopath-0.1.10 layoutparser-0.0.0 portalocker-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Converting the whole pdf into images(page wise)**"
      ],
      "metadata": {
        "id": "pLaguCz1WmF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "images = convert_from_path('/content/utiasset.pdf')\n",
        "!mkdir pages\n",
        "for i in range(len(images)):\n",
        "  images[i].save('pages/page'+str(i)+'.jpg', 'JPEG')"
      ],
      "metadata": {
        "id": "HI1dzCGmkeWI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper code\n"
      ],
      "metadata": {
        "id": "w5MA08E0F8aU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import glob\n",
        "\n",
        "# # Path to the directory containing images\n",
        "# image_folder = \"/content/pages\"  # Change this to your directory\n",
        "\n",
        "# # File extensions to delete\n",
        "# image_extensions = [\"*.jpg\"]\n",
        "\n",
        "# # Delete all images except those starting with \"page\"\n",
        "# for ext in image_extensions:\n",
        "#     for file in glob.glob(os.path.join(image_folder, ext)):\n",
        "#         filename = os.path.basename(file)\n",
        "#         # if not filename.startswith(\"page\"):  # Skip files starting with \"page\"\n",
        "#         os.remove(file)\n",
        "#         print(f\"Deleted: {file}\")\n",
        "#         # else:\n",
        "#         #     print(f\"Skipped: {file}\")\n",
        "\n",
        "# print(\"✅ Cleanup complete!\")\n"
      ],
      "metadata": {
        "id": "Vwb7XBhHEZQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f259a5-acfa-42d2-8eb3-beb50da6efbb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted: /content/pages/page2.jpg\n",
            "Deleted: /content/pages/page1.jpg\n",
            "Deleted: /content/pages/page0.jpg\n",
            "Deleted: /content/pages/page4.jpg\n",
            "Deleted: /content/pages/page9.jpg\n",
            "Deleted: /content/pages/cropped_page9_table.jpg\n",
            "Deleted: /content/pages/page3.jpg\n",
            "Deleted: /content/pages/cropped_page4_table.jpg\n",
            "Deleted: /content/pages/cropped_page5_table.jpg\n",
            "Deleted: /content/pages/page8.jpg\n",
            "Deleted: /content/pages/page6.jpg\n",
            "Deleted: /content/pages/cropped_page3_table.jpg\n",
            "Deleted: /content/pages/page5.jpg\n",
            "Deleted: /content/pages/cropped_page8_table.jpg\n",
            "Deleted: /content/pages/page7.jpg\n",
            "✅ Cleanup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Taking only those images which are having table and cropping that**"
      ],
      "metadata": {
        "id": "dGiaMxdF02QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import layoutparser as lp\n",
        "import os\n",
        "\n",
        "# Function to crop images dynamically and ensure nothing is cut off\n",
        "def crop_images_with_tables(directory_path):\n",
        "    # Load the model once for detecting tables\n",
        "    model = lp.PaddleDetectionLayoutModel(config_path=\"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
        "                                          threshold=0.1,  # Lower threshold for detecting more tables\n",
        "                                          label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"},\n",
        "                                          enforce_cpu=False,\n",
        "                                          enable_mkldnn=True)\n",
        "\n",
        "    # Iterate over all pages in the directory\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith(\".jpg\"):  # Process only .jpg files\n",
        "            image_path = os.path.join(directory_path, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Check if the image is loaded correctly\n",
        "            if image is None:\n",
        "                print(f\"Error loading image {filename}\")\n",
        "                continue\n",
        "\n",
        "            height, width, _ = image.shape  # Get image dimensions\n",
        "\n",
        "            # Detect layout in the image (detect tables, etc.)\n",
        "            layout = model.detect(image)\n",
        "\n",
        "            # Initialize bounding box for cropping\n",
        "            min_x, min_y, max_x, max_y = width, height, 0, 0\n",
        "\n",
        "            # Iterate over detected layout elements\n",
        "            for l in layout:\n",
        "                if l.type == 'Table':\n",
        "                    x_1 = max(0, int(l.block.x_1))  # Ensure within bounds\n",
        "                    y_1 = max(0, int(l.block.y_1))\n",
        "                    x_2 = min(width, int(l.block.x_2))\n",
        "                    y_2 = min(height, int(l.block.y_2))\n",
        "\n",
        "                    # Calculate an adaptive margin (5% of table size)\n",
        "                    margin_x = int((x_2 - x_1) * 0.05)\n",
        "                    margin_y = int((y_2 - y_1) * 0.05)\n",
        "\n",
        "                    min_x = min(min_x, x_1 - margin_x)\n",
        "                    min_y = min(min_y, y_1 - margin_y)\n",
        "                    max_x = max(max_x, x_2 + margin_x)\n",
        "                    max_y = max(max_y, y_2 + margin_y)\n",
        "\n",
        "            # Ensure valid cropping area\n",
        "            if min_x < max_x and min_y < max_y:\n",
        "                min_x = max(0, min_x)\n",
        "                min_y = max(0, min_y)\n",
        "                max_x = min(width, max_x)\n",
        "                max_y = min(height, max_y)\n",
        "\n",
        "                cropped_im = image[min_y:max_y, min_x:max_x]\n",
        "\n",
        "                # Check if the cropped image is valid\n",
        "                if cropped_im.size == 0:\n",
        "                    print(f\"The cropped image is empty for {filename}!\")\n",
        "                else:\n",
        "                    # Save the cropped image\n",
        "                    cropped_image_filename = f\"cropped_{filename.split('.')[0]}_table.jpg\"\n",
        "                    cv2.imwrite(os.path.join(directory_path, cropped_image_filename), cropped_im)\n",
        "                    print(f\"Table cropped from {filename} and saved as {cropped_image_filename}\")\n",
        "            else:\n",
        "                print(f\"No valid table detected in {filename}, no crop performed.\")\n",
        "\n",
        "# Specify the directory containing the images of pages\n",
        "directory_path = \"/content/pages\"\n",
        "crop_images_with_tables(directory_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EQDXSNijCYPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82508eb2-6435-4b02-91c6-d8fea29b2cd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddle-model-ecology.bj.bcebos.com/model/layout-parser/ppyolov2_r50vd_dcn_365e_publaynet.tar to /root/.paddledet/inference_model/ppyolov2_r50vd_dcn_365e_publaynet/ppyolov2_r50vd_dcn_365e_publaynet_infer/ppyolov2_r50vd_dcn_365e_publaynet.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 221M/221M [00:05<00:00, 38.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table cropped from page2.jpg and saved as cropped_page2_table.jpg\n",
            "No valid table detected in page1.jpg, no crop performed.\n",
            "No valid table detected in page0.jpg, no crop performed.\n",
            "Table cropped from page4.jpg and saved as cropped_page4_table.jpg\n",
            "No valid table detected in page3.jpg, no crop performed.\n",
            "No valid table detected in page8.jpg, no crop performed.\n",
            "Table cropped from page6.jpg and saved as cropped_page6_table.jpg\n",
            "Table cropped from page5.jpg and saved as cropped_page5_table.jpg\n",
            "Table cropped from page7.jpg and saved as cropped_page7_table.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGwGhHnd8i_h"
      },
      "source": [
        "# **Converting those selected cropped images to csv**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from paddleocr import PaddleOCR\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize PaddleOCR with improved settings\n",
        "ocr = PaddleOCR(lang='en', rec_algorithm='CRNN')\n",
        "\n",
        "# Function to process each cropped image and generate a structured CSV\n",
        "def process_images_and_generate_csv(directory_path, output_directory):\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    # Iterate over all cropped images in the directory\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.startswith(\"cropped_\") and filename.endswith(\".jpg\"):  # Process only cropped images\n",
        "            cropped_image_path = os.path.join(directory_path, filename)\n",
        "            image_cv = cv2.imread(cropped_image_path)\n",
        "\n",
        "            # Check if the image is loaded correctly\n",
        "            if image_cv is None:\n",
        "                print(f\"Error loading cropped image {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Perform OCR on the cropped image\n",
        "            output = ocr.ocr(cropped_image_path, cls=True)\n",
        "\n",
        "            if not output or not output[0]:  # Ensure OCR detected something\n",
        "                print(f\"No text detected in {filename}, skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Extract bounding boxes, text, and confidence scores\n",
        "            boxes = [line[0] for line in output[0]]\n",
        "            texts = [line[1][0] for line in output[0]]\n",
        "            probabilities = [line[1][1] for line in output[0]]\n",
        "\n",
        "            # Separate horizontal and vertical bounding boxes\n",
        "            horiz_boxes, vert_boxes = [], []\n",
        "            for box in boxes:\n",
        "                x_h, y_h = 0, int(box[0][1])  # Full width, row-based\n",
        "                width_h, height_h = image_cv.shape[1], int(box[2][1] - box[0][1])\n",
        "                horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
        "\n",
        "                x_v, y_v = int(box[0][0]), 0  # Full height, column-based\n",
        "                width_v, height_v = int(box[2][0] - box[0][0]), image_cv.shape[0]\n",
        "                vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
        "\n",
        "            # Convert to tensor format for Non-Maximum Suppression (NMS)\n",
        "            horiz_boxes_tensor = tf.convert_to_tensor(horiz_boxes, dtype=tf.float32)\n",
        "            vert_boxes_tensor = tf.convert_to_tensor(vert_boxes, dtype=tf.float32)\n",
        "            probabilities_tensor = tf.convert_to_tensor(probabilities, dtype=tf.float32)\n",
        "\n",
        "            # Apply NMS for horizontal (rows) and vertical (columns)\n",
        "            horiz_out = tf.image.non_max_suppression(horiz_boxes_tensor, probabilities_tensor, max_output_size=500, iou_threshold=0.2)\n",
        "            vert_out = tf.image.non_max_suppression(vert_boxes_tensor, probabilities_tensor, max_output_size=500, iou_threshold=0.2)\n",
        "\n",
        "            # Sort detected lines and columns properly\n",
        "            horiz_lines = np.sort(np.array(horiz_out))\n",
        "            vert_lines = np.sort(np.array(vert_out))\n",
        "\n",
        "            # Prepare an empty matrix for structured CSV\n",
        "            out_array = [[\"\" for _ in range(len(vert_lines))] for _ in range(len(horiz_lines))]\n",
        "\n",
        "            unordered_boxes = [vert_boxes[i][0] for i in vert_lines]\n",
        "            ordered_boxes = np.argsort(unordered_boxes)\n",
        "\n",
        "            # Helper function: Calculate Intersection over Union (IoU)\n",
        "            def iou(box1, box2):\n",
        "                x1 = max(box1[0], box2[0])\n",
        "                y1 = max(box1[1], box2[1])\n",
        "                x2 = min(box1[2], box2[2])\n",
        "                y2 = min(box1[3], box2[3])\n",
        "                inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "                box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "                box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "                return inter_area / float(box1_area + box2_area - inter_area) if inter_area > 0 else 0\n",
        "\n",
        "            # Assign text to the correct cell in the matrix\n",
        "            for i in range(len(horiz_lines)):\n",
        "                for j in range(len(vert_lines)):\n",
        "                    target_box = [vert_boxes[vert_lines[ordered_boxes[j]]][0], horiz_boxes[horiz_lines[i]][1],\n",
        "                                  vert_boxes[vert_lines[ordered_boxes[j]]][2], horiz_boxes[horiz_lines[i]][3]]\n",
        "                    for b in range(len(boxes)):\n",
        "                        detected_box = [boxes[b][0][0], boxes[b][0][1], boxes[b][2][0], boxes[b][2][1]]\n",
        "                        if iou(target_box, detected_box) > 0.2:\n",
        "                            out_array[i][j] = texts[b]\n",
        "\n",
        "            # Convert the list to a DataFrame\n",
        "            df = pd.DataFrame(out_array)\n",
        "\n",
        "            # Remove empty columns and rows\n",
        "            df = df.loc[:, (df != \"\").any(axis=0)]  # Remove empty columns\n",
        "            df = df.loc[(df != \"\").any(axis=1), :]  # Remove empty rows\n",
        "\n",
        "\n",
        "            # Save to CSV\n",
        "            output_csv_path = os.path.join(output_directory, f\"{filename.split('.')[0]}.csv\")\n",
        "            df.to_csv(output_csv_path, index=False, header=False)\n",
        "            print(f\"✅ Data saved to {output_csv_path}\")\n",
        "\n",
        "# Specify input and output directories\n",
        "directory_path = \"/content/pages\"  # Folder containing cropped images\n",
        "output_directory = \"/content/output_csvs\"  # Folder to save CSVs\n",
        "\n",
        "# Run the function\n",
        "process_images_and_generate_csv(directory_path, output_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8bCZ9AULDZF",
        "outputId": "93c9fcac-e09b-4c13-a35b-6c7f8212fde3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3910/3910 [00:00<00:00, 4741.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to /root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer/en_PP-OCRv4_rec_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:01<00:00, 9952.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2138/2138 [00:00<00:00, 2975.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/02/01 04:47:09] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=True, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='CRNN', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.11/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
            "[2025/02/01 04:47:09] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/02/01 04:47:10] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
            "[2025/02/01 04:47:11] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
            "[2025/02/01 04:47:12] ppocr DEBUG: dt_boxes num : 278, elapsed : 0.38512730598449707\n",
            "[2025/02/01 04:47:12] ppocr DEBUG: rec_res num  : 278, elapsed : 0.9036765098571777\n",
            "✅ Data saved to /content/output_csvs/cropped_page6_table.csv\n",
            "[2025/02/01 04:47:13] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
            "[2025/02/01 04:47:13] ppocr DEBUG: dt_boxes num : 22, elapsed : 0.06377887725830078\n",
            "[2025/02/01 04:47:13] ppocr DEBUG: rec_res num  : 22, elapsed : 0.05519723892211914\n",
            "✅ Data saved to /content/output_csvs/cropped_page7_table.csv\n",
            "[2025/02/01 04:47:13] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
            "[2025/02/01 04:47:13] ppocr DEBUG: dt_boxes num : 14, elapsed : 0.04757213592529297\n",
            "[2025/02/01 04:47:14] ppocr DEBUG: rec_res num  : 14, elapsed : 0.06307554244995117\n",
            "✅ Data saved to /content/output_csvs/cropped_page4_table.csv\n",
            "[2025/02/01 04:47:14] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
            "[2025/02/01 04:47:14] ppocr DEBUG: dt_boxes num : 12, elapsed : 0.041342735290527344\n",
            "[2025/02/01 04:47:14] ppocr DEBUG: rec_res num  : 12, elapsed : 0.06023716926574707\n",
            "✅ Data saved to /content/output_csvs/cropped_page5_table.csv\n",
            "[2025/02/01 04:47:14] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
            "[2025/02/01 04:47:14] ppocr DEBUG: dt_boxes num : 247, elapsed : 0.1419973373413086\n",
            "[2025/02/01 04:47:14] ppocr DEBUG: rec_res num  : 247, elapsed : 0.5902416706085205\n",
            "✅ Data saved to /content/output_csvs/cropped_page2_table.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conveting the csv files into one sinple txt file"
      ],
      "metadata": {
        "id": "Nu_3A0N-1cxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "def csvs_to_single_text(input_directory, output_text_file):\n",
        "    \"\"\"\n",
        "    Merge all CSV files in a directory into a single text file.\n",
        "    - Skips the first column.\n",
        "    - Skips empty rows.\n",
        "    - Ensures no consecutive commas appear.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get all CSV files in the directory\n",
        "    csv_files = [f for f in os.listdir(input_directory) if f.endswith('.csv')]\n",
        "\n",
        "    if not csv_files:\n",
        "        print(\"No CSV files found in the directory.\")\n",
        "        return\n",
        "\n",
        "    with open(output_text_file, mode='w', encoding='utf-8') as out_file:\n",
        "        for file in sorted(csv_files):  # Sort for consistency\n",
        "            csv_file_path = os.path.join(input_directory, file)\n",
        "\n",
        "            with open(csv_file_path, mode='r', encoding='utf-8-sig') as csv_file:\n",
        "                reader = csv.reader(csv_file)\n",
        "\n",
        "                next(reader, None)  # Skip the first row (header)\n",
        "\n",
        "                for row in reader:\n",
        "                    if len(row) > 1:  # Ensure valid row exists\n",
        "                        cleaned_row = [value.strip() for value in row[1:] if value.strip()]  # Remove empty columns\n",
        "                        if cleaned_row:\n",
        "                            line = \"  \".join(cleaned_row)\n",
        "                            line = re.sub(r'\\s*,\\s*', ' , ', line)  # Remove extra spaces around commas\n",
        "                            out_file.write(line + \"\\n\")\n",
        "\n",
        "            out_file.write(\"\\n\" + \"-\" * 50 + \"\\n\")  # Separator for clarity\n",
        "\n",
        "    print(f\"✅ Merged all CSVs into {output_text_file}\")\n",
        "\n",
        "# 🔹 Usage\n",
        "input_directory = \"/content/output_csvs\"  # Update with your CSV directory path\n",
        "output_text_file = \"output.txt\"  # Final merged output file\n",
        "csvs_to_single_text(input_directory, output_text_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ezvRqqlxotx",
        "outputId": "e2cb767f-20dd-4f7b-fc4f-0d6cc8d5b3e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Merged all CSVs into output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langflow  # Install langflow if it's not already installed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tYq7PwQdBHZL",
        "outputId": "76884a37-0d92-422d-9f81-94075fa63843",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langflow\n",
            "  Downloading langflow-1.1.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting ag2>=0.1.0 (from langflow)\n",
            "  Downloading ag2-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting aiofile<4.0.0,>=3.9.0 (from langflow)\n",
            "  Downloading aiofile-3.9.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting arize-phoenix-otel>=0.6.1 (from langflow)\n",
            "  Downloading arize_phoenix_otel-0.7.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting assemblyai==0.35.1 (from langflow)\n",
            "  Downloading assemblyai-0.35.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting astra-assistants~=2.2.9 (from astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading astra_assistants-2.2.9-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting atlassian-python-api==3.41.16 (from langflow)\n",
            "  Downloading atlassian_python_api-3.41.16-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.11/dist-packages (from langflow) (4.12.3)\n",
            "Collecting boto3==1.34.162 (from langflow)\n",
            "  Downloading boto3-1.34.162-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: certifi<2025.0.0,>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from langflow) (2024.12.14)\n",
            "Collecting certifi<2025.0.0,>=2023.11.17 (from langflow)\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting chromadb==0.5.23 (from langflow)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting composio-core==0.6.16 (from langflow)\n",
            "  Downloading composio_core-0.6.16-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting composio-langchain==0.6.16 (from langflow)\n",
            "  Downloading composio_langchain-0.6.16-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting crewai~=0.86.0 (from langflow)\n",
            "  Downloading crewai-0.86.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dspy-ai==2.5.41 (from langflow)\n",
            "  Downloading dspy_ai-2.5.41-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting duckduckgo-search==7.2.1 (from langflow)\n",
            "  Downloading duckduckgo_search-7.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting elasticsearch==8.16.0 (from langflow)\n",
            "  Downloading elasticsearch-8.16.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting faiss-cpu==1.9.0.post1 (from langflow)\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting fake-useragent==1.5.1 (from langflow)\n",
            "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting fastavro==1.9.7 (from langflow)\n",
            "  Downloading fastavro-1.9.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting gitpython==3.1.43 (from langflow)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting google-api-python-client==2.154.0 (from langflow)\n",
            "  Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-search-results<3.0.0,>=2.4.1 (from langflow)\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]<1.0.0,>=0.23.2->langflow) (0.27.1)\n",
            "Collecting jq==1.8.0 (from langflow)\n",
            "  Downloading jq-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting json-repair==0.30.3 (from langflow)\n",
            "  Downloading json_repair-0.30.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting kubernetes==31.0.0 (from langflow)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-anthropic==0.3.0 (from langflow)\n",
            "  Downloading langchain_anthropic-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-astradb==0.5.2 (from langflow)\n",
            "  Downloading langchain_astradb-0.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting langchain-aws==0.2.7 (from langflow)\n",
            "  Downloading langchain_aws-0.2.7-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain-chroma==0.1.4 (from langflow)\n",
            "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting langchain-cohere==0.3.3 (from langflow)\n",
            "  Downloading langchain_cohere-0.3.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-community~=0.3.10 (from langflow)\n",
            "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-elasticsearch==0.3.0 (from langflow)\n",
            "  Downloading langchain_elasticsearch-0.3.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting langchain-google-calendar-tools==0.0.1 (from langflow)\n",
            "  Downloading langchain_google_calendar_tools-0.0.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-google-community==2.0.3 (from langflow)\n",
            "  Downloading langchain_google_community-2.0.3-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-google-genai==2.0.6 (from langflow)\n",
            "  Downloading langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain-google-vertexai==2.0.7 (from langflow)\n",
            "  Downloading langchain_google_vertexai-2.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting langchain-groq==0.2.1 (from langflow)\n",
            "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-milvus==0.1.7 (from langflow)\n",
            "  Downloading langchain_milvus-0.1.7-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-mistralai==0.2.3 (from langflow)\n",
            "  Downloading langchain_mistralai-0.2.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-mongodb==0.2.0 (from langflow)\n",
            "  Downloading langchain_mongodb-0.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-nvidia-ai-endpoints==0.3.5 (from langflow)\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.3.5-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting langchain-ollama==0.2.1 (from langflow)\n",
            "  Downloading langchain_ollama-0.2.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-openai==0.2.12 (from langflow)\n",
            "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-pinecone==0.2.2 (from langflow)\n",
            "  Downloading langchain_pinecone-0.2.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting langchain-unstructured==0.1.5 (from langflow)\n",
            "  Downloading langchain_unstructured-0.1.5-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain==0.3.10 (from langflow)\n",
            "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langflow-base==0.1.3 (from langflow)\n",
            "  Downloading langflow_base-0.1.3-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting langfuse==2.53.9 (from langflow)\n",
            "  Downloading langfuse-2.53.9-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langsmith==0.1.147 (from langflow)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langwatch==0.1.16 (from langflow)\n",
            "  Downloading langwatch-0.1.16-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting lark==1.2.2 (from langflow)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting litellm==1.59.8 (from langflow)\n",
            "  Downloading litellm-1.59.8-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: markdown==3.7 in /usr/local/lib/python3.11/dist-packages (from langflow) (3.7)\n",
            "Requirement already satisfied: markupsafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from langflow) (3.0.2)\n",
            "Collecting mcp>=0.9.1 (from langflow)\n",
            "  Downloading mcp-1.2.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting mem0ai==0.1.34 (from langflow)\n",
            "  Downloading mem0ai-0.1.34-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting metal-sdk==2.5.1 (from langflow)\n",
            "  Downloading metal_sdk-2.5.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting metaphor-python==0.1.23 (from langflow)\n",
            "  Downloading metaphor_python-0.1.23-py3-none-any.whl.metadata (636 bytes)\n",
            "Collecting needle-python>=0.4.0 (from langflow)\n",
            "  Downloading needle_python-0.4.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: networkx==3.4.2 in /usr/local/lib/python3.11/dist-packages (from langflow) (3.4.2)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from langflow) (3.9.1)\n",
            "Requirement already satisfied: numexpr==2.10.2 in /usr/local/lib/python3.11/dist-packages (from langflow) (2.10.2)\n",
            "Collecting openinference-instrumentation-langchain>=0.1.29 (from langflow)\n",
            "  Downloading openinference_instrumentation_langchain-0.1.30-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting opensearch-py==2.8.0 (from langflow)\n",
            "  Downloading opensearch_py-2.8.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pgvector==0.3.6 (from langflow)\n",
            "  Downloading pgvector-0.3.6-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pyarrow==17.0.0 in /usr/local/lib/python3.11/dist-packages (from langflow) (17.0.0)\n",
            "Collecting pydantic-ai>=0.0.19 (from langflow)\n",
            "  Downloading pydantic_ai-0.0.21-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pydantic-settings==2.4.0 (from langflow)\n",
            "  Downloading pydantic_settings-2.4.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pymongo==4.10.1 (from langflow)\n",
            "  Downloading pymongo-4.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pytube==15.0.0 (from langflow)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting qdrant-client==1.9.2 (from langflow)\n",
            "  Downloading qdrant_client-1.9.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting qianfan==0.3.5 (from langflow)\n",
            "  Downloading qianfan-0.3.5-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting ragstack-ai-knowledge-store==0.2.1 (from langflow)\n",
            "  Downloading ragstack_ai_knowledge_store-0.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting redis==5.2.1 (from langflow)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting scrapegraph-py>=1.10.2 (from langflow)\n",
            "  Downloading scrapegraph_py-1.10.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting spider-client==0.1.24 (from langflow)\n",
            "  Downloading spider-client-0.1.24.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.36 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[aiosqlite,postgresql-psycopg2binary,postgresql-psycopgbinary]<3.0.0,>=2.0.36->langflow) (2.0.37)\n",
            "Collecting sseclient-py==1.8.0 (from langflow)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting supabase==2.6.0 (from langflow)\n",
            "  Downloading supabase-2.6.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting types-cachetools==5.5.0.20240820 (from langflow)\n",
            "  Downloading types_cachetools-5.5.0.20240820-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting upstash-vector==0.6.0 (from langflow)\n",
            "  Downloading upstash_vector-0.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting uv>=0.5.7 (from langflow)\n",
            "  Downloading uv-0.5.26-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting weaviate-client==4.10.2 (from langflow)\n",
            "  Downloading weaviate_client-4.10.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting wikipedia==1.4.0 (from langflow)\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wolframalpha==5.1.3 (from langflow)\n",
            "  Downloading wolframalpha-5.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting yfinance==0.2.50 (from langflow)\n",
            "  Downloading yfinance-0.2.50-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting youtube-transcript-api==0.6.3 (from langflow)\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting zep-python==2.0.2 (from langflow)\n",
            "  Downloading zep_python-2.0.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: httpx>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai==0.35.1->langflow) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.10.17 in /usr/local/lib/python3.11/dist-packages (from assemblyai==0.35.1->langflow) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.11/dist-packages (from assemblyai==0.35.1->langflow) (4.12.2)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai==0.35.1->langflow) (14.2)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from atlassian-python-api==3.41.16->langflow) (1.2.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from atlassian-python-api==3.41.16->langflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from atlassian-python-api==3.41.16->langflow) (1.17.0)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.11/dist-packages (from atlassian-python-api==3.41.16->langflow) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from atlassian-python-api==3.41.16->langflow) (1.3.1)\n",
            "Collecting jmespath (from atlassian-python-api==3.41.16->langflow)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4==4.12.3->langflow) (2.6)\n",
            "Collecting botocore<1.35.0,>=1.34.162 (from boto3==1.34.162->langflow)\n",
            "  Downloading botocore-1.34.162-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3==1.34.162->langflow)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting build>=1.0.3 (from chromadb==0.5.23->langflow)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.5.23->langflow)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb==0.5.23->langflow)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->langflow)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.5.23->langflow)\n",
            "  Downloading posthog-3.11.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.23->langflow)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.23->langflow)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.23->langflow)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (1.16.0)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb==0.5.23->langflow)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb==0.5.23->langflow)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb==0.5.23->langflow)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==0.5.23->langflow)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (0.15.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb==0.5.23->langflow)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (3.10.15)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->langflow) (13.9.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from composio-core==0.6.16->langflow) (3.11.11)\n",
            "Requirement already satisfied: jsonschema<5,>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from composio-core==0.6.16->langflow) (4.23.0)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from composio-core==0.6.16->langflow) (2.20.0)\n",
            "Collecting pysher==1.0.8 (from composio-core==0.6.16->langflow)\n",
            "  Downloading Pysher-1.0.8.tar.gz (9.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.11/dist-packages (from composio-core==0.6.16->langflow) (8.6.1)\n",
            "Collecting jsonref>=1.1.0 (from composio-core==0.6.16->langflow)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting inflection>=0.5.1 (from composio-core==0.6.16->langflow)\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting semver>=2.13.0 (from composio-core==0.6.16->langflow)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from composio-core==0.6.16->langflow) (8.1.8)\n",
            "Requirement already satisfied: pyperclip<2,>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from composio-core==0.6.16->langflow) (1.9.0)\n",
            "Collecting paramiko>=3.4.1 (from composio-core==0.6.16->langflow)\n",
            "  Downloading paramiko-3.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting langchainhub>=0.1.15 (from composio-langchain==0.6.16->langflow)\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting dspy>=2.5.3 (from dspy-ai==2.5.41->langflow)\n",
            "  Downloading dspy-2.6.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting primp>=0.10.0 (from duckduckgo-search==7.2.1->langflow)\n",
            "  Downloading primp-0.11.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search==7.2.1->langflow) (5.3.0)\n",
            "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch==8.16.0->langflow)\n",
            "  Downloading elastic_transport-8.17.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu==1.9.0.post1->langflow) (24.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython==3.1.43->langflow) (4.0.12)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==2.154.0->langflow) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==2.154.0->langflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==2.154.0->langflow) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==2.154.0->langflow) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==2.154.0->langflow) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes==31.0.0->langflow) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes==31.0.0->langflow) (1.8.0)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes==31.0.0->langflow) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes==31.0.0->langflow)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10->langflow) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10->langflow) (0.3.5)\n",
            "Collecting anthropic<1,>=0.39.0 (from langchain-anthropic==0.3.0->langflow)\n",
            "  Downloading anthropic-0.45.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from langchain-anthropic==0.3.0->langflow) (0.7.1)\n",
            "Collecting astrapy<2.0.0,>=1.5.2 (from langchain-astradb==0.5.2->langflow)\n",
            "  Downloading astrapy-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere==0.3.3->langflow)\n",
            "  Downloading cohere-5.13.11-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere==0.3.3->langflow)\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere==0.3.3->langflow) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere==0.3.3->langflow) (0.9.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-calendar-tools==0.0.1->langflow) (1.2.1)\n",
            "Collecting protobuf>=4.25.0 (from langchain-google-calendar-tools==0.0.1->langflow)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: pytz>=2023.3.post1 in /usr/local/lib/python3.11/dist-packages (from langchain-google-calendar-tools==0.0.1->langflow) (2024.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-google-community==2.0.3->langflow) (2.4.1)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai==2.0.6->langflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai==2.0.6->langflow) (0.8.4)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.70.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai==2.0.7->langflow) (1.74.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai==2.0.7->langflow) (2.19.0)\n",
            "Collecting httpx>=0.19.0 (from assemblyai==0.35.1->langflow)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-google-vertexai==2.0.7->langflow)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq==0.2.1->langflow)\n",
            "  Downloading groq-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pymilvus<3.0.0,>=2.4.3 (from langchain-milvus==0.1.7->langflow)\n",
            "  Downloading pymilvus-2.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pillow<11.0.0,>=10.0.0 (from langchain-nvidia-ai-endpoints==0.3.5->langflow)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting ollama<1,>=0.3.0 (from langchain-ollama==0.2.1->langflow)\n",
            "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.12->langflow) (1.59.9)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.12->langflow)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting aiohttp (from composio-core==0.6.16->langflow)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting langchain-tests<0.4.0,>=0.3.7 (from langchain-pinecone==0.2.2->langflow)\n",
            "  Downloading langchain_tests-0.3.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pinecone<6.0.0,>=5.4.0 (from langchain-pinecone==0.2.2->langflow)\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting unstructured-client<0.26.0,>=0.25.0 (from langchain-unstructured==0.1.5->langflow)\n",
            "  Downloading unstructured_client-0.25.9-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<25.0.0,>=24.1.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aiosqlite>=0.20.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting alembic<2.0.0,>=1.13.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting asyncer<1.0.0,>=0.0.5 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==0.5.23->langflow)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: cachetools<6.0.0,>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (5.5.1)\n",
            "Requirement already satisfied: chardet<6.0.0,>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (5.2.0)\n",
            "Collecting clickhouse-connect==0.7.19 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading clickhouse_connect-0.7.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: cryptography<44.0.0,>=42.0.5 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (43.0.3)\n",
            "Collecting diskcache<6.0.0,>=5.6.3 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (0.16)\n",
            "Requirement already satisfied: duckdb<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (1.1.3)\n",
            "Collecting emoji<3.0.0,>=2.12.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting fastapi-pagination<1.0.0,>=0.12.29 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading fastapi_pagination-0.12.34-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.15.4 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (3.17.0)\n",
            "Collecting firecrawl-py<2.0.0,>=1.0.16 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading firecrawl_py-1.11.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting grandalf<1.0.0,>=0.8.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: greenlet>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (3.1.1)\n",
            "Collecting gunicorn<24.0.0,>=22.0.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting loguru<1.0.0,>=0.7.1 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting multiprocess<1.0.0,>=0.70.14 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting nanoid<3.0.0,>=2.0.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading nanoid-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (1.6.0)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.5.23->langflow)\n",
            "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-prometheus<1.0.0,>=0.46b0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.50b0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.5.23->langflow)\n",
            "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb==0.5.23->langflow)\n",
            "  Downloading orjson-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting passlib<2.0.0,>=1.7.4 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading passlib-1.7.4-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (4.3.6)\n",
            "Requirement already satisfied: prometheus-client<1.0.0,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (0.21.1)\n",
            "Collecting pypdf~=5.1.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-docx<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (1.1.2)\n",
            "Collecting python-jose<4.0.0,>=3.3.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading python_jose-3.3.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting python-multipart<1.0.0,>=0.0.12 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: setuptools<76.0.0,>=70 in /usr/local/lib/python3.11/dist-packages (from langflow-base==0.1.3->langflow) (75.1.0)\n",
            "Collecting sqlmodel==0.0.22 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading sqlmodel-0.0.22-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting uncurl<1.0.0,>=0.0.11 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading uncurl-0.0.11-py3-none-any.whl.metadata (300 bytes)\n",
            "Collecting validators>=0.34.0 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting anyio<5.0.0,>=4.4.0 (from langfuse==2.53.9->langflow)\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting backoff>=1.10.0 (from langfuse==2.53.9->langflow)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: idna<4.0,>=3.7 in /usr/local/lib/python3.11/dist-packages (from langfuse==2.53.9->langflow) (3.10)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.11/dist-packages (from langfuse==2.53.9->langflow) (1.17.2)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith==0.1.147->langflow) (1.0.0)\n",
            "Collecting coolname<3.0.0,>=2.2.0 (from langwatch==0.1.16->langflow)\n",
            "  Downloading coolname-2.2.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting retry<0.10.0,>=0.9.2 (from langwatch==0.1.16->langflow)\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.59.8->langflow) (3.1.5)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm==1.59.8->langflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1->langflow) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1->langflow) (2024.11.6)\n",
            "Collecting Events (from opensearch-py==2.8.0->langflow)\n",
            "  Downloading Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo==4.10.1->langflow)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client==1.9.2->langflow)\n",
            "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client==1.9.2->langflow)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting aiolimiter>=1.1.0 (from qianfan==0.3.5->langflow)\n",
            "  Downloading aiolimiter-1.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting bce-python-sdk>=0.8.79 (from qianfan==0.3.5->langflow)\n",
            "  Downloading bce_python_sdk-0.9.25-py3-none-any.whl.metadata (315 bytes)\n",
            "Collecting clevercsv (from qianfan==0.3.5->langflow)\n",
            "  Downloading clevercsv-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting ijson (from qianfan==0.3.5->langflow)\n",
            "  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.38 in /usr/local/lib/python3.11/dist-packages (from qianfan==0.3.5->langflow) (3.0.50)\n",
            "Collecting tenacity>=8.2.3 (from chromadb==0.5.23->langflow)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting cassio<0.2.0,>=0.1.7 (from ragstack-ai-knowledge-store==0.2.1->langflow)\n",
            "  Downloading cassio-0.1.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting gotrue<3.0,>=1.3 (from supabase==2.6.0->langflow)\n",
            "  Downloading gotrue-2.11.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting postgrest<0.17.0,>=0.14 (from supabase==2.6.0->langflow)\n",
            "  Downloading postgrest-0.16.11-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting realtime<2.0.0,>=1.0.0 (from supabase==2.6.0->langflow)\n",
            "  Downloading realtime-1.0.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting storage3<0.8.0,>=0.5.3 (from supabase==2.6.0->langflow)\n",
            "  Downloading storage3-0.7.7-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting supafunc<0.6.0,>=0.3.1 (from supabase==2.6.0->langflow)\n",
            "  Downloading supafunc-0.5.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client==4.10.2->langflow)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client==4.10.2->langflow)\n",
            "  Downloading grpcio_health_checking-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting xmltodict (from wolframalpha==5.1.3->langflow)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from wolframalpha==5.1.3->langflow) (10.5.0)\n",
            "Collecting jaraco.context (from wolframalpha==5.1.3->langflow)\n",
            "  Downloading jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: multidict in /usr/local/lib/python3.11/dist-packages (from wolframalpha==5.1.3->langflow) (6.1.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.50->langflow) (0.0.11)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.50->langflow) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.50->langflow) (3.17.8)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.50->langflow) (1.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from clickhouse-connect==0.7.19->langflow-base==0.1.3->langflow) (0.23.0)\n",
            "Collecting lz4 (from clickhouse-connect==0.7.19->langflow-base==0.1.3->langflow)\n",
            "  Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere==0.3.3->langflow) (2025.1)\n",
            "Collecting pyautogen==0.7.3 (from ag2>=0.1.0->langflow)\n",
            "  Downloading pyautogen-0.7.3-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting docker (from pyautogen==0.7.3->ag2>=0.1.0->langflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fast-depends<3,>=2.4.12 (from pyautogen==0.7.3->ag2>=0.1.0->langflow)\n",
            "  Downloading fast_depends-2.4.12-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.3->ag2>=0.1.0->langflow) (2.5.0)\n",
            "Collecting caio<0.10.0,>=0.9.0 (from aiofile<4.0.0,>=3.9.0->langflow)\n",
            "  Downloading caio-0.9.21-cp311-cp311-manylinux_2_34_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting openinference-instrumentation>=0.1.21 (from arize-phoenix-otel>=0.6.1->langflow)\n",
            "  Downloading openinference_instrumentation-0.1.21-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting openinference-semantic-conventions>=0.1.9 (from arize-phoenix-otel>=0.6.1->langflow)\n",
            "  Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting opentelemetry-exporter-otlp (from arize-phoenix-otel>=0.6.1->langflow)\n",
            "  Downloading opentelemetry_exporter_otlp-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-proto>=1.12.0 (from arize-phoenix-otel>=0.6.1->langflow)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.11/dist-packages (from arize-phoenix-otel>=0.6.1->langflow) (0.37b0)\n",
            "Collecting lsprotocol<2024.0.0,>=2023.0.1 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading lsprotocol-2023.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting python-lsp-jsonrpc<2.0.0,>=1.1.2 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading python_lsp_jsonrpc-1.1.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting ruff<9.0.0,>=0.6.2 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting tree-sitter<0.24.0,>=0.23.0 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading tree_sitter-0.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
            "Collecting tree-sitter-python<0.24.0,>=0.23.0 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading tree_sitter_python-0.23.6-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting e2b<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading e2b-1.0.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting e2b-code-interpreter<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading e2b_code_interpreter-1.0.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting appdirs>=1.4.4 (from crewai~=0.86.0->langflow)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python>=4.7.1 (from crewai~=0.86.0->langflow)\n",
            "  Downloading auth0_python-4.8.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting crewai-tools>=0.17.0 (from crewai~=0.86.0->langflow)\n",
            "  Downloading crewai_tools-0.33.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting instructor>=1.3.3 (from crewai~=0.86.0->langflow)\n",
            "  Downloading instructor-1.7.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai~=0.86.0->langflow) (3.1.5)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai~=0.86.0->langflow)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai~=0.86.0->langflow)\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyvis>=0.3.2 (from crewai~=0.86.0->langflow)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tomli-w>=1.1.0 (from crewai~=0.86.0->langflow)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from crewai~=0.86.0->langflow) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.23.2->huggingface-hub[inference]<1.0.0,>=0.23.2->langflow) (2024.10.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community~=0.3.10->langflow)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community~=0.3.10 (from langflow)\n",
            "  Downloading langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "INFO: pip is looking at multiple versions of mcp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mcp>=0.9.1 (from langflow)\n",
            "  Downloading mcp-1.2.0-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading mcp-1.1.3-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp>=0.9.1->langflow)\n",
            "  Downloading sse_starlette-2.2.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting starlette>=0.27 (from mcp>=0.9.1->langflow)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-instrumentation (from openinference-instrumentation-langchain>=0.1.29->langflow)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting pydantic-ai-slim==0.0.21 (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.21->pydantic-ai>=0.0.19->langflow)\n",
            "  Downloading pydantic_ai_slim-0.0.21-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-ai-slim==0.0.21->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.21->pydantic-ai>=0.0.19->langflow) (0.2.2)\n",
            "Collecting griffe>=1.3.2 (from pydantic-ai-slim==0.0.21->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.21->pydantic-ai>=0.0.19->langflow)\n",
            "  Downloading griffe-1.5.6-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting logfire-api>=1.2.0 (from pydantic-ai-slim==0.0.21->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.21->pydantic-ai>=0.0.19->langflow)\n",
            "  Downloading logfire_api-3.4.0-py3-none-any.whl.metadata (971 bytes)\n",
            "Collecting pydantic-graph==0.0.21 (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.21->pydantic-ai>=0.0.19->langflow)\n",
            "  Downloading pydantic_graph-0.0.21-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting mistralai>=1.2.5 (from pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.21->pydantic-ai>=0.0.19->langflow)\n",
            "  Downloading mistralai-1.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client==2.154.0->langflow)\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting psycopg2-binary (from sqlalchemy[aiosqlite,postgresql-psycopg2binary,postgresql-psycopgbinary]<3.0.0,>=2.0.36->langflow)\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting psycopg>=3.0.7 (from psycopg[binary]>=3.0.7; extra == \"postgresql-psycopgbinary\"->sqlalchemy[aiosqlite,postgresql-psycopg2binary,postgresql-psycopgbinary]<3.0.0,>=2.0.36->langflow)\n",
            "  Downloading psycopg-3.2.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->composio-core==0.6.16->langflow) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->composio-core==0.6.16->langflow) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->composio-core==0.6.16->langflow) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->composio-core==0.6.16->langflow) (1.5.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->composio-core==0.6.16->langflow) (1.18.3)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.0->langflow-base==0.1.3->langflow)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow) (1.3.1)\n",
            "Collecting deprecation<2.2.0,>=2.1.0 (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow) (0.10.2)\n",
            "Collecting uuid6>=2024.1.12 (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow)\n",
            "  Downloading uuid6-2024.7.10-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai~=0.86.0->langflow) (2.10.1)\n",
            "Collecting pycryptodome>=3.8.0 (from bce-python-sdk>=0.8.79->qianfan==0.3.5->langflow)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from bce-python-sdk>=0.8.79->qianfan==0.3.5->langflow) (1.0.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb==0.5.23->langflow)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting cassandra-driver<4.0.0,>=3.28.0 (from cassio<0.2.0,>=0.1.7->ragstack-ai-knowledge-store==0.2.1->langflow)\n",
            "  Downloading cassandra_driver-3.29.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.3->langflow) (2.27.2)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.3->langflow)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "INFO: pip is looking at multiple versions of crewai-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting crewai-tools>=0.17.0 (from crewai~=0.86.0->langflow)\n",
            "  Downloading crewai_tools-0.32.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading crewai_tools-0.32.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading crewai_tools-0.25.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting docx2txt>=0.8 (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting embedchain>=0.1.114 (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading embedchain-0.1.126-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading lancedb-0.18.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting linkup-sdk>=0.2.1 (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading linkup_sdk-0.2.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pyright>=1.1.350 (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading pyright-1.1.393-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pytest>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow) (8.3.4)\n",
            "Collecting selenium>=4.18.1 (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting serpapi>=0.1.5 (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting crewai-tools>=0.17.0 (from crewai~=0.86.0->langflow)\n",
            "  Downloading crewai_tools-0.25.7-py3-none-any.whl.metadata (5.1 kB)\n",
            "  Downloading crewai_tools-0.25.6-py3-none-any.whl.metadata (5.1 kB)\n",
            "  Downloading crewai_tools-0.25.5-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44.0.0,>=42.0.5->langflow-base==0.1.3->langflow) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community~=0.3.10->langflow)\n",
            "  Downloading marshmallow-3.26.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community~=0.3.10->langflow)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from dspy>=2.5.3->dspy-ai==2.5.41->langflow) (3.1.1)\n",
            "Collecting datasets (from dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "INFO: pip is looking at multiple versions of dspy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dspy>=2.5.3 (from dspy-ai==2.5.41->langflow)\n",
            "  Downloading dspy-2.5.43-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading dspy-2.5.42-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.41-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.40-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.39-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.38-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.37-py3-none-any.whl.metadata (7.2 kB)\n",
            "INFO: pip is still looking at multiple versions of dspy to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dspy-2.5.36-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.35-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.34-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.33-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading dspy-2.5.32-py3-none-any.whl.metadata (7.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading dspy-2.5.31-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading dspy-2.5.30-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading dspy-2.5.29-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.28-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.27-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.26-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.25-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.24-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.23-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.22-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.21-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.20-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.19-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.18-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.17-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.16-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.15-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.14-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.13-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.12-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.11-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.10-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.9-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.8-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dspy-2.5.7-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna (from dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting structlog (from dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading structlog-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting ujson (from dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting magicattr~=0.1.6 (from dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpcore<2.0.0,>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from e2b<2.0.0,>=1.0.1->astra-assistants[tools]~=2.2.9->langflow) (1.0.7)\n",
            "Collecting simsimd>=3 (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch==0.3.0->langflow)\n",
            "  Downloading simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython==3.1.43->langflow) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.154.0->langflow) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.154.0->langflow) (1.26.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client==2.154.0->langflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client==2.154.0->langflow) (4.9)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow) (2.0.6)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai==2.0.7->langflow) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai==2.0.7->langflow) (1.6.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.6->langflow) (0.6.15)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf<1.0.0,>=0.8.0->langflow-base==0.1.3->langflow) (3.2.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance==0.2.50->langflow) (0.5.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore<2.0.0,>=1.0.5->e2b<2.0.0,>=1.0.1->astra-assistants[tools]~=2.2.9->langflow) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]<1.0.0,>=0.27->langflow-base==0.1.3->langflow)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.8.1->composio-core==0.6.16->langflow) (3.21.0)\n",
            "INFO: pip is looking at multiple versions of instructor to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting instructor>=1.3.3 (from crewai~=0.86.0->langflow)\n",
            "  Downloading instructor-1.7.1-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading instructor-1.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow)\n",
            "  Downloading jiter-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting instructor>=1.3.3 (from crewai~=0.86.0->langflow)\n",
            "  Downloading instructor-1.6.4-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading instructor-1.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow)\n",
            "  Downloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting instructor>=1.3.3 (from crewai~=0.86.0->langflow)\n",
            "  Downloading instructor-1.6.2-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading instructor-1.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading instructor-1.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "INFO: pip is still looking at multiple versions of instructor to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading instructor-1.5.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4.21.1->composio-core==0.6.16->langflow) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4.21.1->composio-core==0.6.16->langflow) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4.21.1->composio-core==0.6.16->langflow) (0.22.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10->langflow) (1.33)\n",
            "Collecting langchain-core<0.4.0,>=0.3.22 (from langchain==0.3.10->langflow)\n",
            "  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow)\n",
            "  Downloading pytest_asyncio-0.25.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow)\n",
            "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting syrupy<5,>=4 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow)\n",
            "  Downloading syrupy-4.8.1-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting cattrs!=23.2.1 (from lsprotocol<2024.0.0,>=2023.0.1->astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
            "  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting dill>=0.3.9 (from multiprocess<1.0.0,>=0.70.14->langflow-base==0.1.3->langflow)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.5.23->langflow)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23->langflow) (25.1.24)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23->langflow) (1.13.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai~=0.86.0->langflow) (2.0.0)\n",
            "Collecting importlib-metadata>=4.8.1 (from composio-core==0.6.16->langflow)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23->langflow)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->langflow)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-semantic-conventions (from arize-phoenix-otel>=0.6.1->langflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->langflow)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->langflow)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting pynacl>=1.5 (from paramiko>=3.4.1->composio-core==0.6.16->langflow)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber>=0.11.4->crewai~=0.86.0->langflow)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai~=0.86.0->langflow)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber>=0.11.4->crewai~=0.86.0->langflow) (3.4.1)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone<6.0.0,>=5.4.0->langchain-pinecone==0.2.2->langflow)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone<6.0.0,>=5.4.0->langchain-pinecone==0.2.2->langflow)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting strenum<0.5.0,>=0.4.9 (from postgrest<0.17.0,>=0.14->supabase==2.6.0->langflow)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.5.23->langflow)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit>=3.0.38->qianfan==0.3.5->langflow) (0.2.13)\n",
            "Collecting psycopg-binary==3.2.4 (from psycopg[binary]>=3.0.7; extra == \"postgresql-psycopgbinary\"->sqlalchemy[aiosqlite,postgresql-psycopg2binary,postgresql-psycopgbinary]<3.0.0,>=2.0.36->langflow)\n",
            "  Downloading psycopg_binary-3.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai==0.35.1->langflow) (0.7.0)\n",
            "INFO: pip is looking at multiple versions of pymilvus to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pymilvus<3.0.0,>=2.4.3 (from langchain-milvus==0.1.7->langflow)\n",
            "  Downloading pymilvus-2.5.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading pymilvus-2.5.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading pymilvus-2.5.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading pymilvus-2.5.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading pymilvus-2.4.14-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading pymilvus-2.4.13-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading pymilvus-2.4.12-py3-none-any.whl.metadata (5.7 kB)\n",
            "INFO: pip is still looking at multiple versions of pymilvus to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading pymilvus-2.4.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading pymilvus-2.4.10-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Downloading pymilvus-2.4.9-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting environs<=9.5.0 (from pymilvus<3.0.0,>=2.4.3->langchain-milvus==0.1.7->langflow)\n",
            "  Downloading environs-9.5.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting milvus-lite<2.5.0,>=2.4.0 (from pymilvus<3.0.0,>=2.4.3->langchain-milvus==0.1.7->langflow)\n",
            "  Downloading milvus_lite-2.4.11-py3-none-manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting ecdsa!=0.15 (from python-jose<4.0.0,>=3.3.0->langflow-base==0.1.3->langflow)\n",
            "  Downloading ecdsa-0.19.0-py2.py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.11/dist-packages (from python-jose<4.0.0,>=3.3.0->langflow-base==0.1.3->langflow) (0.6.1)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai~=0.86.0->langflow) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai~=0.86.0->langflow) (4.0.1)\n",
            "INFO: pip is looking at multiple versions of realtime to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting realtime<2.0.0,>=1.0.0 (from supabase==2.6.0->langflow)\n",
            "  Downloading realtime-1.0.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading realtime-1.0.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading realtime-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading realtime-1.0.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading realtime-1.0.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading realtime-1.0.0-py3-none-any.whl.metadata (492 bytes)\n",
            "Collecting firecrawl-py<2.0.0,>=1.0.16 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading firecrawl_py-1.10.2-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is still looking at multiple versions of realtime to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading firecrawl_py-1.10.1-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.8.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.7.1-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.6.8-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.6.7-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.6.4-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.6.3-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.6.2-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.6.1-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.6.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.5.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading firecrawl_py-1.3.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading firecrawl_py-1.3.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading firecrawl_py-1.2.4-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading firecrawl_py-1.2.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting asyncio (from firecrawl-py<2.0.0,>=1.0.16->langflow-base==0.1.3->langflow)\n",
            "  Downloading asyncio-3.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting firecrawl-py<2.0.0,>=1.0.16 (from langflow-base==0.1.3->langflow)\n",
            "  Downloading firecrawl_py-1.2.2-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading firecrawl_py-1.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading firecrawl_py-1.2.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading firecrawl_py-1.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading firecrawl_py-1.1.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting ag2>=0.1.0 (from langflow)\n",
            "  Downloading ag2-0.7.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting websockets>=11.0 (from assemblyai==0.35.1->langflow)\n",
            "  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pyautogen==0.7.2 (from ag2>=0.1.0->langflow)\n",
            "  Downloading pyautogen-0.7.2-py3-none-any.whl.metadata (30 kB)\n",
            "INFO: pip is looking at multiple versions of pyautogen to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ag2>=0.1.0 (from langflow)\n",
            "  Downloading ag2-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pyautogen==0.7.1 (from ag2>=0.1.0->langflow)\n",
            "  Downloading pyautogen-0.7.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting flaml (from pyautogen==0.7.1->ag2>=0.1.0->langflow)\n",
            "  Downloading FLAML-2.3.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ag2>=0.1.0 (from langflow)\n",
            "  Downloading ag2-0.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pyautogen==0.7.0 (from ag2>=0.1.0->langflow)\n",
            "  Downloading pyautogen-0.7.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting ag2>=0.1.0 (from langflow)\n",
            "  Downloading ag2-0.6.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pyautogen==0.6.1 (from ag2>=0.1.0->langflow)\n",
            "  Downloading pyautogen-0.6.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting ag2>=0.1.0 (from langflow)\n",
            "  Downloading ag2-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pyautogen==0.6.0 (from ag2>=0.1.0->langflow)\n",
            "  Downloading pyautogen-0.6.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting ag2>=0.1.0 (from langflow)\n",
            "  Downloading ag2-0.5.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pyautogen==0.5.3 (from ag2>=0.1.0->langflow)\n",
            "  Downloading pyautogen-0.5.3-py3-none-any.whl.metadata (25 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is still looking at multiple versions of crewai-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from retry<0.10.0,>=0.9.2->langwatch==0.1.16->langflow) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry<0.10.0,>=0.9.2->langwatch==0.1.16->langflow)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.5.23->langflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.5.23->langflow) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.5.23->langflow) (1.5.4)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured==0.1.5->langflow)\n",
            "  Downloading deepdiff-8.1.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured==0.1.5->langflow)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured==0.1.5->langflow)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->langflow)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->langflow)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->langflow)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting backports.tarfile (from jaraco.context->wolframalpha==5.1.3->langflow)\n",
            "  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver<4.0.0,>=3.28.0->cassio<0.2.0,>=0.1.7->ragstack-ai-knowledge-store==0.2.1->langflow)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=42.0.5->langflow-base==0.1.3->langflow) (2.22)\n",
            "Collecting orderly-set<6,>=5.2.3 (from deepdiff>=6.0->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured==0.1.5->langflow)\n",
            "  Downloading orderly_set-5.2.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting embedchain>=0.1.114 (from crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading embedchain-0.1.125-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.12->langflow)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow) (1.62.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow) (0.14.0)\n",
            "Collecting colorama>=0.4 (from griffe>=1.3.2->pydantic-ai-slim==0.0.21->pydantic-ai-slim[anthropic,cohere,graph,groq,mistral,openai,vertexai]==0.0.21->pydantic-ai>=0.0.19->langflow)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<1.0.0,>=0.27->langflow-base==0.1.3->langflow)\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<1.0.0,>=0.27->langflow-base==0.1.3->langflow)\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai~=0.86.0->langflow)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai~=0.86.0->langflow) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai~=0.86.0->langflow) (5.7.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai~=0.86.0->langflow) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai~=0.86.0->langflow) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai~=0.86.0->langflow) (4.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain==0.3.10->langflow) (3.0.0)\n",
            "Collecting pylance==0.22.0 (from lancedb>=0.5.4->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading pylance-0.22.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.5.23->langflow) (0.1.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=8.0.0->crewai-tools>=0.17.0->crewai~=0.86.0->langflow) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=8.0.0->crewai-tools>=0.17.0->crewai~=0.86.0->langflow) (1.5.0)\n",
            "Collecting trio~=0.17 (from selenium>=4.18.1->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium>=4.18.1->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->composio-core==0.6.16->langflow) (0.2.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.23->langflow)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets (from dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pyarrow-hotfix (from datasets->dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting datasets (from dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
            "INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.14.3-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.14.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.14.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.14.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.13.2-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.13.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.10.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.6.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.5.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.3.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.3.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.2.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting xxhash (from datasets->dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting responses<0.19 (from datasets->dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting colorlog (from optuna->dspy>=2.5.3->dspy-ai==2.5.41->langflow)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.23->langflow) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai~=0.86.0->langflow) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai~=0.86.0->langflow) (0.7.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium>=4.18.1->crewai-tools>=0.17.0->crewai~=0.86.0->langflow)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium>=4.18.1->crewai-tools>=0.17.0->crewai~=0.86.0->langflow) (1.7.1)\n",
            "Downloading langflow-1.1.3-py3-none-any.whl (6.0 kB)\n",
            "Downloading assemblyai-0.35.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading atlassian_python_api-3.41.16-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.9/177.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.34.162-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading composio_core-0.6.16-py3-none-any.whl (467 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.8/467.8 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading composio_langchain-0.6.16-py3-none-any.whl (4.8 kB)\n",
            "Downloading dspy_ai-2.5.41-py3-none-any.whl (339 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.7/339.7 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-7.2.1-py3-none-any.whl (19 kB)\n",
            "Downloading elasticsearch-8.16.0-py3-none-any.whl (543 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.1/543.1 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
            "Downloading fastavro-1.9.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_python_client-2.154.0-py2.py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jq-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.6/746.6 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.30.3-py3-none-any.whl (18 kB)\n",
            "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.10-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-0.3.0-py3-none-any.whl (22 kB)\n",
            "Downloading langchain_astradb-0.5.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_aws-0.2.7-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
            "Downloading langchain_cohere-0.3.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_elasticsearch-0.3.0-py3-none-any.whl (24 kB)\n",
            "Downloading langchain_google_calendar_tools-0.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading langchain_google_community-2.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.6/77.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.6-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_vertexai-2.0.7-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_milvus-0.1.7-py3-none-any.whl (23 kB)\n",
            "Downloading langchain_mistralai-0.2.3-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_mongodb-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading langchain_nvidia_ai_endpoints-0.3.5-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_ollama-0.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_pinecone-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading langchain_unstructured-0.1.5-py3-none-any.whl (7.0 kB)\n",
            "Downloading langflow_base-0.1.3-py3-none-any.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langfuse-2.53.9-py3-none-any.whl (222 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.0/222.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langwatch-0.1.16-py3-none-any.whl (30 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.59.8-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.34-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading metal_sdk-2.5.1-py3-none-any.whl (14 kB)\n",
            "Downloading metaphor_python-0.1.23-py3-none-any.whl (6.1 kB)\n",
            "Downloading opensearch_py-2.8.0-py3-none-any.whl (353 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.5/353.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pgvector-0.3.6-py3-none-any.whl (24 kB)\n",
            "Downloading pydantic_settings-2.4.0-py3-none-any.whl (23 kB)\n",
            "Downloading pymongo-4.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qdrant_client-1.9.2-py3-none-any.whl (230 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/230.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qianfan-0.3.5-py3-none-any.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.8/304.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ragstack_ai_knowledge_store-0.2.1-py3-none-any.whl (18 kB)\n",
            "Downloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading supabase-2.6.0-py3-none-any.whl (16 kB)\n",
            "Downloading types_cachetools-5.5.0.20240820-py3-none-any.whl (4.1 kB)\n",
            "Downloading upstash_vector-0.6.0-py3-none-any.whl (15 kB)\n",
            "Downloading weaviate_client-4.10.2-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wolframalpha-5.1.3-py3-none-any.whl (6.3 kB)\n",
            "Downloading yfinance-0.2.50-py2.py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zep_python-2.0.2-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clickhouse_connect-0.7.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlmodel-0.0.22-py3-none-any.whl (28 kB)\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading firecrawl_py-1.11.0-py3-none-any.whl (18 kB)\n",
            "Downloading realtime-1.0.6-py3-none-any.whl (9.0 kB)\n",
            "Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ag2-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading pyautogen-0.5.3-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofile-3.9.0-py3-none-any.whl (19 kB)\n",
            "Downloading arize_phoenix_otel-0.7.1-py3-none-any.whl (11 kB)\n",
            "Downloading astra_assistants-2.2.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai-0.86.0-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.10-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.1.3-py3-none-any.whl (36 kB)\n",
            "Downloading needle_python-0.4.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading openinference_instrumentation_langchain-0.1.30-py3-none-any.whl (17 kB)\n",
            "Downloading pydantic_ai-0.0.21-py3-none-any.whl (9.8 kB)\n",
            "Downloading pydantic_ai_slim-0.0.21-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.5/90.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_graph-0.0.21-py3-none-any.whl (16 kB)\n",
            "Downloading scrapegraph_py-1.10.2-py3-none-any.whl (14 kB)\n",
            "Downloading uv-0.5.26-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiolimiter-1.2.1-py3-none-any.whl (6.7 kB)\n",
            "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
            "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.45.2-py3-none-any.whl (222 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.8/222.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading astrapy-1.5.2-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading auth0_python-4.8.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.0/134.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bce_python_sdk-0.9.25-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.34.162-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading caio-0.9.21-cp311-cp311-manylinux_2_34_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.1/78.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cassio-0.1.10-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.13.11-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading coolname-2.2.0-py2.py3-none-any.whl (37 kB)\n",
            "Downloading crewai_tools-0.25.5-py3-none-any.whl (514 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.8/514.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dspy-2.5.7-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.0/305.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading e2b-1.0.6-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading e2b_code_interpreter-1.0.5-py3-none-any.whl (12 kB)\n",
            "Downloading elastic_transport-8.17.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_pagination-0.12.34-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gotrue-2.11.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.16.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.70.0-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Downloading instructor-1.5.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_tests-0.3.10-py3-none-any.whl (37 kB)\n",
            "Downloading langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lsprotocol-2023.0.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.17-py311-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nanoid-2.0.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
            "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openinference_instrumentation-0.1.21-py3-none-any.whl (19 kB)\n",
            "Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl (9.1 kB)\n",
            "Downloading opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.29.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_prometheus-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading paramiko-3.5.0-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading passlib-1.7.4-py2.py3-none-any.whl (525 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.6/525.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading postgrest-0.16.11-py3-none-any.whl (21 kB)\n",
            "Downloading posthog-3.11.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.11.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg-3.2.4-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.7/198.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg_binary-3.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymilvus-2.4.9-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_jose-3.3.0-py2.py3-none-any.whl (33 kB)\n",
            "Downloading python_lsp_jsonrpc-1.1.2-py3-none-any.whl (8.8 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading sse_starlette-2.2.1-py3-none-any.whl (10 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading storage3-0.7.7-py3-none-any.whl (16 kB)\n",
            "Downloading supafunc-0.5.1-py3-none-any.whl (6.4 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading tree_sitter-0.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (567 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.6/567.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tree_sitter_python-0.23.6-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uncurl-0.0.11-py3-none-any.whl (7.4 kB)\n",
            "Downloading unstructured_client-0.25.9-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clevercsv-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
            "Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.29.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading cassandra_driver-3.29.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-8.1.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ecdsa-0.19.0-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.3/149.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.125-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
            "Downloading griffe-1.5.6-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading lancedb-0.18.0-cp39-abi3-manylinux_2_28_x86_64.whl (32.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.2/32.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.22.0-cp39-abi3-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading logfire_api-3.4.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
            "Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading milvus_lite-2.4.11-py3-none-manylinux2014_x86_64.whl (45.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistralai-1.5.0-py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.393-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_asyncio-0.25.3-py3-none-any.whl (19 kB)\n",
            "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Downloading simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (632 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading syrupy-4.8.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uuid6-2024.7.10-py3-none-any.whl (6.4 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.2.1-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.3.3-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.2/314.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading structlog-25.1.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.9/68.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Downloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading orderly_set-5.2.3-py3-none-any.whl (12 kB)\n",
            "Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: spider-client, wikipedia, pysher, google-search-results, pypika, docx2txt\n",
            "  Building wheel for spider-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spider-client: filename=spider_client-0.1.24-py3-none-any.whl size=13084 sha256=d8ed9a990305caf9743c0594d8a1abef54f77e039cd5481bfe59caf3396bf8dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/59/2c/1b8b474a303839a4b9c5bfe78a541cfb1a9b174b64d29cf182\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=a993dfe9a8afdf0ace08c343afbd7040acbcd396885d4e4f508b227c18d86299\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "  Building wheel for pysher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysher: filename=Pysher-1.0.8-py3-none-any.whl size=9889 sha256=156932292751ab502f1f7f88ac7c1326dd6f691fffa89f518635ce6489353559\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/f8/4a/46e34939a44ed8992d6931a3358b547b048aa987c0e7c6d551\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=518429abdc26607c9d6e3583dcbd713c32301e1c44f9e2856875cb43428ada75\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=517ee99aa80790e916c907e1321a1070940a61511f6311a1f8ca92dcbe9cf85b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=ce8aa0ce29ea03eeaf4dbb6f5883993bea2310ead5e388b4db0d05c6ce34905a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0e/7a/3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
            "Successfully built spider-client wikipedia pysher google-search-results pypika docx2txt\n",
            "Installing collected packages: strenum, sseclient-py, sortedcontainers, simsimd, schema, pypika, passlib, nanoid, monotonic, magicattr, ijson, filetype, fake-useragent, Events, durationpy, docx2txt, coolname, appdirs, xxhash, xmltodict, wsproto, websockets, validators, uvloop, uvicorn, uv, uuid6, uncurl, ujson, types-requests, types-cachetools, tree-sitter-python, tree-sitter, tomli-w, tenacity, structlog, semver, ruff, redis, pytube, python-multipart, python-dotenv, pysbd, pyproject_hooks, pypdfium2, pypdf, pycryptodome, py, psycopg2-binary, psycopg-binary, psycopg, protobuf, primp, portalocker, pinecone-plugin-interface, pillow, pgvector, overrides, outcome, orjson, orderly-set, opentelemetry-util-http, openinference-semantic-conventions, nodeenv, mypy-extensions, mmh3, milvus-lite, marshmallow, Mako, lz4, loguru, logfire-api, lark, jsonref, jsonpath-python, json-repair, jq, jmespath, jiter, jedi, inflection, importlib-metadata, hyperframe, humanfriendly, httpx-sse, httptools, hpack, gunicorn, grandalf, geomet, flaml, fastavro, faiss-cpu, emoji, ecdsa, dnspython, diskcache, dill, deprecation, colorlog, colorama, clevercsv, chroma-hnswlib, certifi, cattrs, caio, bcrypt, backports.tarfile, backoff, asgiref, anyio, aiosqlite, aiolimiter, aiofiles, watchfiles, typing-inspect, trio, syrupy, starlette, retry, realtime, python-lsp-jsonrpc, python-jose, pytest-socket, pytest-asyncio, pyright, pynacl, pymongo, pylance, pinecone-plugin-inference, opentelemetry-proto, opentelemetry-api, multiprocess, lsprotocol, jaraco.context, h2, grpcio-tools, grpcio-health-checking, griffe, google-auth, gitpython, environs, elastic-transport, duckduckgo-search, deepdiff, coloredlogs, clickhouse-connect, cassandra-driver, build, botocore, bce-python-sdk, asyncer, alembic, aiohttp, aiofile, youtube-transcript-api, yfinance, wikipedia, trio-websocket, tiktoken, sse-starlette, sqlmodel, spider-client, serpapi, scrapegraph-py, s3transfer, responses, pyvis, pysher, pymilvus, pydantic-settings, posthog, pinecone, pdfminer.six, paramiko, optuna, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, opensearch-py, onnxruntime, needle-python, metaphor-python, langchainhub, lancedb, httpx, gptcache, google-search-results, firecrawl-py, fastapi-pagination, fastapi, elasticsearch, docker, dataclasses-json, cassio, authlib, auth0-python, zep-python, wolframalpha, weaviate-client, upstash-vector, unstructured-client, tokenizers, selenium, ragstack-ai-knowledge-store, qianfan, pydantic-graph, pydantic-ai-slim, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation, ollama, mistralai, metal-sdk, mcp, langwatch, langsmith, langfuse, kubernetes, groq, google-api-python-client, e2b, datasets, composio-core, boto3, atlassian-python-api, assemblyai, anthropic, supafunc, storage3, qdrant-client, pyautogen, postgrest, opentelemetry-instrumentation-asgi, opentelemetry-exporter-prometheus, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation, litellm, langchain-core, instructor, gotrue, e2b-code-interpreter, cohere, astrapy, supabase, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp, openinference-instrumentation-langchain, mem0ai, langchain-unstructured, langchain-tests, langchain-openai, langchain-ollama, langchain-nvidia-ai-endpoints, langchain-mongodb, langchain-mistralai, langchain-milvus, langchain-groq, langchain-elasticsearch, langchain-aws, langchain-anthropic, dspy, astra-assistants, ag2, pydantic-ai, langchain-pinecone, langchain-google-vertexai, langchain-google-genai, langchain, dspy-ai, chromadb, arize-phoenix-otel, langchain-google-calendar-tools, langchain-community, langchain-chroma, composio-langchain, langchain-google-community, langchain-experimental, langchain-astradb, langflow-base, langchain-cohere, embedchain, crewai-tools, crewai, langflow\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.2\n",
            "    Uninstalling websockets-14.2:\n",
            "      Successfully uninstalled websockets-14.2\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.0\n",
            "    Uninstalling protobuf-3.20.0:\n",
            "      Successfully uninstalled protobuf-3.20.0\n",
            "  Attempting uninstall: portalocker\n",
            "    Found existing installation: portalocker 3.1.1\n",
            "    Uninstalling portalocker-3.1.1:\n",
            "      Successfully uninstalled portalocker-3.1.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.10.15\n",
            "    Uninstalling orjson-3.10.15:\n",
            "      Successfully uninstalled orjson-3.10.15\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.8.2\n",
            "    Uninstalling jiter-0.8.2:\n",
            "      Successfully uninstalled jiter-0.8.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.12.14\n",
            "    Uninstalling certifi-2024.12.14:\n",
            "      Successfully uninstalled certifi-2024.12.14\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.27.0\n",
            "    Uninstalling google-auth-2.27.0:\n",
            "      Successfully uninstalled google-auth-2.27.0\n",
            "  Attempting uninstall: gitpython\n",
            "    Found existing installation: GitPython 3.1.44\n",
            "    Uninstalling GitPython-3.1.44:\n",
            "      Successfully uninstalled GitPython-3.1.44\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.11\n",
            "    Uninstalling aiohttp-3.11.11:\n",
            "      Successfully uninstalled aiohttp-3.11.11\n",
            "  Attempting uninstall: yfinance\n",
            "    Found existing installation: yfinance 0.2.52\n",
            "    Uninstalling yfinance-0.2.52:\n",
            "      Successfully uninstalled yfinance-0.2.52\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.2\n",
            "    Uninstalling langsmith-0.3.2:\n",
            "      Successfully uninstalled langsmith-0.3.2\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.155.0\n",
            "    Uninstalling google-api-python-client-2.155.0:\n",
            "      Successfully uninstalled google-api-python-client-2.155.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.32\n",
            "    Uninstalling langchain-core-0.3.32:\n",
            "      Successfully uninstalled langchain-core-0.3.32\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.16\n",
            "    Uninstalling langchain-0.3.16:\n",
            "      Successfully uninstalled langchain-0.3.16\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.38.0 which is incompatible.\n",
            "google-genai 0.3.0 requires websockets<15.0dev,>=13.0, but you have websockets 12.0 which is incompatible.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.8.0 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Events-0.5 Mako-1.3.8 ag2-0.5.3 aiofile-3.9.0 aiofiles-24.1.0 aiohttp-3.10.11 aiolimiter-1.2.1 aiosqlite-0.20.0 alembic-1.14.1 anthropic-0.45.2 anyio-4.8.0 appdirs-1.4.4 arize-phoenix-otel-0.7.1 asgiref-3.8.1 assemblyai-0.35.1 astra-assistants-2.2.9 astrapy-1.5.2 asyncer-0.0.8 atlassian-python-api-3.41.16 auth0-python-4.8.0 authlib-1.3.1 backoff-2.2.1 backports.tarfile-1.2.0 bce-python-sdk-0.9.25 bcrypt-4.0.1 boto3-1.34.162 botocore-1.34.162 build-1.2.2.post1 caio-0.9.21 cassandra-driver-3.29.2 cassio-0.1.10 cattrs-24.1.2 certifi-2024.8.30 chroma-hnswlib-0.7.6 chromadb-0.5.23 clevercsv-0.8.3 clickhouse-connect-0.7.19 cohere-5.13.11 colorama-0.4.6 coloredlogs-15.0.1 colorlog-6.9.0 composio-core-0.6.16 composio-langchain-0.6.16 coolname-2.2.0 crewai-0.86.0 crewai-tools-0.25.5 dataclasses-json-0.6.7 datasets-2.2.1 deepdiff-8.1.1 deprecation-2.1.0 dill-0.3.9 diskcache-5.6.3 dnspython-2.7.0 docker-7.1.0 docx2txt-0.8 dspy-2.5.7 dspy-ai-2.5.41 duckduckgo-search-7.2.1 durationpy-0.9 e2b-1.0.6 e2b-code-interpreter-1.0.5 ecdsa-0.19.0 elastic-transport-8.17.0 elasticsearch-8.16.0 embedchain-0.1.125 emoji-2.14.1 environs-9.5.0 faiss-cpu-1.9.0.post1 fake-useragent-1.5.1 fastapi-0.115.8 fastapi-pagination-0.12.34 fastavro-1.9.7 filetype-1.2.0 firecrawl-py-1.11.0 flaml-2.3.3 geomet-0.2.1.post1 gitpython-3.1.43 google-api-python-client-2.154.0 google-auth-2.38.0 google-search-results-2.4.2 gotrue-2.11.3 gptcache-0.1.44 grandalf-0.8 griffe-1.5.6 groq-0.16.0 grpcio-health-checking-1.70.0 grpcio-tools-1.70.0 gunicorn-23.0.0 h2-4.1.0 hpack-4.1.0 httptools-0.6.4 httpx-0.27.2 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.1.0 ijson-3.3.0 importlib-metadata-8.5.0 inflection-0.5.1 instructor-1.5.2 jaraco.context-6.0.1 jedi-0.19.2 jiter-0.5.0 jmespath-1.0.1 jq-1.8.0 json-repair-0.30.3 jsonpath-python-1.0.6 jsonref-1.1.0 kubernetes-31.0.0 lancedb-0.18.0 langchain-0.3.10 langchain-anthropic-0.3.0 langchain-astradb-0.5.2 langchain-aws-0.2.7 langchain-chroma-0.1.4 langchain-cohere-0.3.3 langchain-community-0.3.10 langchain-core-0.3.33 langchain-elasticsearch-0.3.0 langchain-experimental-0.3.4 langchain-google-calendar-tools-0.0.1 langchain-google-community-2.0.3 langchain-google-genai-2.0.6 langchain-google-vertexai-2.0.7 langchain-groq-0.2.1 langchain-milvus-0.1.7 langchain-mistralai-0.2.3 langchain-mongodb-0.2.0 langchain-nvidia-ai-endpoints-0.3.5 langchain-ollama-0.2.1 langchain-openai-0.2.12 langchain-pinecone-0.2.2 langchain-tests-0.3.10 langchain-unstructured-0.1.5 langchainhub-0.1.21 langflow-1.1.3 langflow-base-0.1.3 langfuse-2.53.9 langsmith-0.1.147 langwatch-0.1.16 lark-1.2.2 litellm-1.59.8 logfire-api-3.4.0 loguru-0.7.3 lsprotocol-2023.0.1 lz4-4.4.3 magicattr-0.1.6 marshmallow-3.26.0 mcp-1.1.3 mem0ai-0.1.34 metal-sdk-2.5.1 metaphor-python-0.1.23 milvus-lite-2.4.11 mistralai-1.5.0 mmh3-5.1.0 monotonic-1.6 multiprocess-0.70.17 mypy-extensions-1.0.0 nanoid-2.0.0 needle-python-0.4.0 nodeenv-1.9.1 ollama-0.4.7 onnxruntime-1.20.1 openinference-instrumentation-0.1.21 openinference-instrumentation-langchain-0.1.30 openinference-semantic-conventions-0.1.12 opensearch-py-2.8.0 opentelemetry-api-1.29.0 opentelemetry-exporter-otlp-1.29.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-exporter-otlp-proto-http-1.29.0 opentelemetry-exporter-prometheus-0.50b0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 opentelemetry-util-http-0.50b0 optuna-4.2.0 orderly-set-5.2.3 orjson-3.10.0 outcome-1.3.0.post0 overrides-7.7.0 paramiko-3.5.0 passlib-1.7.4 pdfminer.six-20231228 pdfplumber-0.11.5 pgvector-0.3.6 pillow-10.4.0 pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pinecone-plugin-interface-0.0.7 portalocker-2.10.1 postgrest-0.16.11 posthog-3.11.0 primp-0.11.0 protobuf-5.29.3 psycopg-3.2.4 psycopg-binary-3.2.4 psycopg2-binary-2.9.10 py-1.11.0 pyautogen-0.5.3 pycryptodome-3.21.0 pydantic-ai-0.0.21 pydantic-ai-slim-0.0.21 pydantic-graph-0.0.21 pydantic-settings-2.4.0 pylance-0.22.0 pymilvus-2.4.9 pymongo-4.10.1 pynacl-1.5.0 pypdf-5.1.0 pypdfium2-4.30.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.393 pysbd-0.3.4 pysher-1.0.8 pytest-asyncio-0.25.3 pytest-socket-0.7.0 python-dotenv-1.0.1 python-jose-3.3.0 python-lsp-jsonrpc-1.1.2 python-multipart-0.0.20 pytube-15.0.0 pyvis-0.3.2 qdrant-client-1.9.2 qianfan-0.3.5 ragstack-ai-knowledge-store-0.2.1 realtime-1.0.6 redis-5.2.1 responses-0.18.0 retry-0.9.2 ruff-0.9.4 s3transfer-0.10.4 schema-0.7.7 scrapegraph-py-1.10.2 selenium-4.28.1 semver-3.0.4 serpapi-0.1.5 simsimd-6.2.1 sortedcontainers-2.4.0 spider-client-0.1.24 sqlmodel-0.0.22 sse-starlette-2.2.1 sseclient-py-1.8.0 starlette-0.45.3 storage3-0.7.7 strenum-0.4.15 structlog-25.1.0 supabase-2.6.0 supafunc-0.5.1 syrupy-4.8.1 tenacity-8.5.0 tiktoken-0.7.0 tokenizers-0.20.3 tomli-w-1.2.0 tree-sitter-0.23.2 tree-sitter-python-0.23.6 trio-0.28.0 trio-websocket-0.11.1 types-cachetools-5.5.0.20240820 types-requests-2.32.0.20241016 typing-inspect-0.9.0 ujson-5.10.0 uncurl-0.0.11 unstructured-client-0.25.9 upstash-vector-0.6.0 uuid6-2024.7.10 uv-0.5.26 uvicorn-0.34.0 uvloop-0.21.0 validators-0.34.0 watchfiles-1.0.4 weaviate-client-4.10.2 websockets-12.0 wikipedia-1.4.0 wolframalpha-5.1.3 wsproto-1.2.0 xmltodict-0.14.2 xxhash-3.5.0 yfinance-0.2.50 youtube-transcript-api-0.6.3 zep-python-2.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "google",
                  "googleapiclient",
                  "importlib_metadata",
                  "jaraco",
                  "portalocker"
                ]
              },
              "id": "80e614d1cb934350b808c14daacd9ce4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Automated Financial Data Extraction Using Langflow API**"
      ],
      "metadata": {
        "id": "Kj-SpYet11qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import argparse\n",
        "import requests\n",
        "from argparse import RawTextHelpFormatter\n",
        "from typing import Optional\n",
        "import warnings\n",
        "\n",
        "try:\n",
        "    from langflow.load import upload_file\n",
        "except ImportError:\n",
        "    warnings.warn(\"Langflow provides a function to help you upload files to the flow. Please install langflow to use it.\")\n",
        "    upload_file = None\n",
        "\n",
        "BASE_API_URL = \"https://api.langflow.astra.datastax.com\"\n",
        "LANGFLOW_ID = \"c6d524b3-2ff0-4e73-b765-449e37ffe560\"\n",
        "FLOW_ID = \"8327ee1c-0964-4c74-8a5c-73948095f523\"\n",
        "APPLICATION_TOKEN = \"AstraCS:jGUxqLLrjRBRMFZIGizOhEoA:d473d5249f470a4b6589ad16930b9f215589465d73ecdaa3ab4b70e86fb55cda\"\n",
        "ENDPOINT = \"\"  # Set a specific endpoint if needed\n",
        "\n",
        "TWEAKS = {\n",
        "    \"Prompt-byv20\": {},\n",
        "    \"ChatOutput-QPTF5\": {},\n",
        "    \"ChatInput-Cljjm\": {},\n",
        "    \"GroqModel-hTdjo\": {}\n",
        "}\n",
        "\n",
        "def run_flow(message: str, endpoint: str, output_type: str = \"chat\", input_type: str = \"chat\",\n",
        "             tweaks: Optional[dict] = None, application_token: Optional[str] = None) -> dict:\n",
        "    \"\"\"\n",
        "    Run a flow with a given message and optional tweaks.\n",
        "\n",
        "    :param message: The message to send to the flow\n",
        "    :param endpoint: The ID or the endpoint name of the flow\n",
        "    :param tweaks: Optional tweaks to customize the flow\n",
        "    :return: The JSON response from the flow\n",
        "    \"\"\"\n",
        "    api_url = f\"{BASE_API_URL}/lf/{LANGFLOW_ID}/api/v1/run/{endpoint}\"\n",
        "\n",
        "    payload = {\n",
        "        \"input_value\": message,\n",
        "        \"output_type\": output_type,\n",
        "        \"input_type\": input_type,\n",
        "    }\n",
        "    headers = None\n",
        "    if tweaks:\n",
        "        payload[\"tweaks\"] = tweaks\n",
        "    if application_token:\n",
        "        headers = {\"Authorization\": \"Bearer \" + application_token, \"Content-Type\": \"application/json\"}\n",
        "    response = requests.post(api_url, json=payload, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "def main():\n",
        "    # Instead of parsing command-line arguments, define variables directly\n",
        "    output_file = \"output.txt\"  # Path to the text file\n",
        "    endpoint = ENDPOINT or FLOW_ID  # Flow ID or endpoint\n",
        "    tweaks = TWEAKS  # Tweaks for the flow\n",
        "    application_token = APPLICATION_TOKEN  # Authentication token\n",
        "    output_type = \"chat\"  # Output type\n",
        "    input_type = \"chat\"  # Input type\n",
        "    upload_file_path = None  # Path to file to upload\n",
        "    components = None  # Components for upload\n",
        "\n",
        "    if not os.path.exists(output_file):\n",
        "        raise FileNotFoundError(f\"❌ The file '{output_file}' does not exist. Ensure the CSV processing step has been completed.\")\n",
        "\n",
        "    with open(output_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        message = file.read().strip()\n",
        "\n",
        "\n",
        "    if upload_file_path:\n",
        "        if not upload_file:\n",
        "            raise ImportError(\"Langflow is not installed. Please install it to use the upload_file function.\")\n",
        "        elif not components:\n",
        "            raise ValueError(\"You need to provide the components to upload the file to.\")\n",
        "        tweaks = upload_file(file_path=upload_file_path, host=BASE_API_URL, flow_id=ENDPOINT, components=components, tweaks=tweaks)\n",
        "\n",
        "    response = run_flow(\n",
        "        message=message,\n",
        "        endpoint=endpoint,\n",
        "        output_type=output_type,\n",
        "        input_type=input_type,\n",
        "        tweaks=tweaks,\n",
        "        application_token=application_token\n",
        "    )\n",
        "\n",
        "    #print(json.dumps(response, indent=2))\n",
        "    print(response['outputs'][0]['outputs'][0]['results']['message']['data']['text'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "      main()\n"
      ],
      "metadata": {
        "id": "p5dwYeH1dvHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6404b507-ccf3-4bf4-badb-ce10c86dc05c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided financial statements, I will extract the key financial metrics for the latest quarter (December 31, 2024) from the \"Unaudited Consolidated Statement of Profit and Loss\" table.\n",
            "\n",
            "**Revenue/Sales:**\n",
            "```json\n",
            "{\n",
            "  \"Revenue\": 417.58,\n",
            "  \"Total Revenue\": 417.58,\n",
            "  \"Sales Revenue\": 375.39,\n",
            "  \"Net Sales\": 375.39,\n",
            "  \"Gross Sales\": 375.39,\n",
            "  \"Turnover\": 417.58,\n",
            "  \"Top-line Revenue\": 417.58,\n",
            "  \"Total Sales\": 417.58,\n",
            "  \"Operating Revenue\": 417.58\n",
            "}\n",
            "```\n",
            "\n",
            "**Operating Profit (EBIT/Profit Before Tax):**\n",
            "```json\n",
            "{\n",
            "  \"Operating Profit\": 221.19,\n",
            "  \"Operating Income\": 221.19,\n",
            "  \"Earnings Before Interest & Taxes (EBIT)\": 221.19,\n",
            "  \"Profit from Operations\": 221.19,\n",
            "  \"Operating Earnings\": 221.19,\n",
            "  \"Core Business Profit\": 221.19,\n",
            "  \"Income from Continuing Operations\": 221.19,\n",
            "  \"EBITDA (Earnings Before Interest, Taxes, Depreciation, and Amortization)\": 221.19\n",
            "}\n",
            "```\n",
            "\n",
            "**Net Profit (PAT/Profit After Tax):**\n",
            "```json\n",
            "{\n",
            "  \"Net Profit\": 150.69,\n",
            "  \"Net Income\": 150.69,\n",
            "  \"Bottom-line Profit\": 150.69,\n",
            "  \"Earnings After Tax (EAT)\": 150.69,\n",
            "  \"Profit After Tax (PAT)\": 150.69,\n",
            "  \"Net Earnings\": 150.69,\n",
            "  \"Total Comprehensive Income\": 173.59,\n",
            "  \"Net Surplus\": 150.69,\n",
            "  \"Final Profit\": 150.69,\n",
            "  \"Retained Profit\": 150.69\n",
            "}\n",
            "```\n",
            "\n",
            "Here are the extracted financial metrics in a single JSON object:\n",
            "```json\n",
            "{\n",
            "  \"Revenue\": 417.58,\n",
            "  \"Operating Profit\": 221.19,\n",
            "  \"Net Profit\": 150.69\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PilqCuWJ22dz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}